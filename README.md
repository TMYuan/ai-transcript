# AI Transcript

> AI-powered video transcription with Whisper and VAD for accurate subtitle generation

Generate high-quality subtitles from video or audio files using OpenAI's Whisper model with intelligent voice activity detection (VAD) for optimal accuracy.

## Features

- **ğŸ¯ High Accuracy**: Combines Silero VAD + Faster-Whisper for precise speech detection and transcription
- **âš¡ GPU Accelerated**: CUDA support with 2.8x faster processing (GTX 1080 tested)
- **ğŸ“ Multiple Formats**: Export to SRT or VTT subtitle formats
- **ğŸ¬ Video & Audio**: Supports MP4, AVI, MKV, MOV, WAV, MP3, FLAC, and more
- **ğŸ› ï¸ Flexible Models**: Choose from tiny to large Whisper models based on accuracy/speed needs
- **ğŸŒ Multi-language**: Supports 99+ languages including English, Chinese, Spanish, French, etc.
- **ğŸ’» Clean CLI**: Professional command-line interface with progress indicators
- **ğŸ§ª Well Tested**: 206 tests with comprehensive coverage

## Installation

### Prerequisites

- Python 3.9 or higher
- [uv](https://github.com/astral-sh/uv) (recommended) or pip
- FFmpeg (for video processing)
- CUDA-capable GPU (optional, for acceleration)

### Install with uv (Recommended)

```bash
# Clone repository
git clone https://github.com/TMYuan/ai-transcript.git
cd ai-transcript

# Install dependencies
uv sync

# Install FFmpeg (if not already installed)
# Ubuntu/Debian:
sudo apt install ffmpeg
# macOS:
brew install ffmpeg
```

### Install with pip

```bash
git clone https://github.com/TMYuan/ai-transcript.git
cd ai-transcript
pip install -e .
```

## Quick Start

```bash
# Basic usage (auto-detects GPU)
uv run aitranscript transcribe video.mp4

# Specify model size and device
uv run aitranscript transcribe video.mp4 --model medium --device cuda

# Generate VTT format with custom output
uv run aitranscript transcribe audio.wav --format vtt -o subtitles.vtt

# Transcribe in Chinese
uv run aitranscript transcribe video.mp4 --language zh
```

## CLI Usage

### Transcribe Command

```bash
uv run aitranscript transcribe [OPTIONS] INPUT_FILE
```

**Options:**

| Option | Description | Default |
|--------|-------------|---------|
| `-o, --output PATH` | Output subtitle file path | Auto-generated |
| `--model MODEL` | Whisper model size: tiny, base, small, medium, large | medium |
| `--device DEVICE` | Compute device: cuda, cpu | cuda |
| `--format FORMAT` | Subtitle format: srt, vtt | srt |
| `--language CODE` | Language code (en, zh, es, fr, etc.) | en |
| `-q, --quiet` | Minimal output (no progress bars) | - |
| `-v, --verbose` | Detailed logging for debugging | - |

**Examples:**

```bash
# Fast transcription with tiny model on CPU
uv run aitranscript transcribe video.mp4 --model tiny --device cpu

# High accuracy with large model on GPU
uv run aitranscript transcribe video.mp4 --model large --device cuda

# Quiet mode for scripting
uv run aitranscript transcribe video.mp4 --quiet -o output.srt

# Verbose output for debugging
uv run aitranscript transcribe video.mp4 --verbose
```

### Help

```bash
# Show help
uv run aitranscript --help

# Show transcribe command help
uv run aitranscript transcribe --help

# Show version
uv run aitranscript --version
```

## Supported Formats

**Video:** MP4, AVI, MKV, MOV, FLV, WMV, WebM
**Audio:** WAV, MP3, FLAC, AAC, OGG, M4A

## Project Structure

```
ai-transcript/
â”œâ”€â”€ src/aitranscript/
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â””â”€â”€ main.py              # Click-based CLI interface
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ audio_extractor.py   # Video â†’ Audio extraction
â”‚   â”‚   â”œâ”€â”€ transcriber.py       # Whisper transcription
â”‚   â”‚   â”œâ”€â”€ vad_processor.py     # Speech detection with Silero VAD
â”‚   â”‚   â””â”€â”€ subtitle_generator.py # SRT/VTT generation
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration dataclasses
â”‚   â”‚   â””â”€â”€ segment.py           # Speech/Transcript segments
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ transcription_pipeline.py # End-to-end orchestration
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ file_utils.py        # File operations
â”‚       â”œâ”€â”€ validators.py        # Input/output validation
â”‚       â””â”€â”€ logger.py            # Centralized logging
â”œâ”€â”€ tests/                       # Comprehensive test suite (206 tests)
â”œâ”€â”€ pyproject.toml               # Project configuration
â””â”€â”€ README.md                    # This file
```

## License

MIT License - see LICENSE file for details.

## Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) - Speech recognition model
- [Faster-Whisper](https://github.com/guillaumekln/faster-whisper) - Optimized Whisper implementation
- [Silero VAD](https://github.com/snakers4/silero-vad) - Voice activity detection
- [Click](https://click.palletsprojects.com/) - CLI framework
- [Rich](https://rich.readthedocs.io/) - Terminal formatting

## Support

- **Issues**: [GitHub Issues](https://github.com/TMYuan/ai-transcript/issues)
- **Discussions**: [GitHub Discussions](https://github.com/TMYuan/ai-transcript/discussions)
